{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blank-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Latex\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-impact",
   "metadata": {},
   "source": [
    "### GAN Architecture\n",
    "\n",
    "The explanation consists of the flow as mention in published [paper](https://arxiv.org/pdf/1406.2661.pdf) by Ian Goodfellow. The images are own visual understandings to remember. \n",
    "\n",
    "* General Overview of the GAN\n",
    "* Value Function\n",
    "* Global Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-defense",
   "metadata": {},
   "source": [
    "* Consists of 2-networks that fight with each other\n",
    "    - Generator\n",
    "    - Discrinator\n",
    "* These networks are trying constantly to counterfeit with each other \n",
    "* One network is trying to generate fake images and other is trying to catch the fake ones\n",
    "* The counterfeit is *generator* and cop who's trying to catch the fake images is the discriminator\n",
    "* The Generator keeps generating fake images until it completely becomes perfect in fooling the cop\n",
    "* So, Generator is trying to maximize the probability of Discriminator making a mistake\n",
    "\n",
    "This is the broad overview of the model, diving into the details\n",
    "* The Generator tries to learn the joint probability of input and output given by following equation\n",
    "\n",
    "    P(X,Y) = ($P(X|Y)P(Y), P(Y|X)P(X)$)\n",
    "    \n",
    "* The Discriminator tries to learn the output given input variable\n",
    "\n",
    "    P(Y|X=x)\n",
    "\n",
    "* The adversial modelling is applied to Multilayered Perceptrons \n",
    "\n",
    "$\\theta_g$ and $\\theta_d$ are nothing but weights. $P_{(data)}(x)$ is the original data and $P_g(x)$  is the probability of noise obtained after passing the noise distribution $P_z(z)$ into generator network, which randomly samples using the generator weights. The discriminator judges the output based on the input passed through it by outputting $y=0$ and $y=1$ \n",
    "\n",
    "\n",
    "<img src=\"../../images/image4.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "Error Function for this can be explained very intuitively for this!\n",
    "Natural logarithm is used to calculate the error. In general, if output is closer to the input then error should be minimum. That is, say \n",
    "\n",
    "* if $x=1$ and $y=0.9$ then the error should be minimal. \n",
    "* if $x=0$ and $y=3$ then the error should be maximal.\n",
    "\n",
    "This behaviour can be observed in natural logarithm as below.\n",
    "\n",
    "<img src=\"../../images/image2.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "The above error function can be adapted for generator. \n",
    "\n",
    "\n",
    "In a same way for discriminator, acting as a cop. This is expected to perform reverse of what generator has performed. This can be observed by below graph\n",
    "\n",
    "<img src=\"../../images/image3.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "So in general for Generator and Discriminator. The forward pass and loss function can be explained by given diagram.\n",
    "\n",
    "\n",
    "<img src=\"../../images/image1.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "\n",
    "\n",
    "These explanations are very intuitive\n",
    "\n",
    "A bigger and fancier cost function can be given as below:\n",
    "\n",
    "$J(\\theta)=-\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}h_{\\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\\theta}(x^{(i)})]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-guarantee",
   "metadata": {},
   "source": [
    "### Code Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 32\n",
    "num_epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-happening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-overhead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-vaccine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-heather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-lesbian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-friendly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-ballot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-circulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
